from train import run_training
TRAIN_SKETCH_DIR = "../envs/drawing_env/training/sketches/"
VALIDATION_SKETCH_DIR = "../envs/drawing_env/training/validation_sketches/"

experiments = [
    {
        "VERSION": "20251023_square_envs16_1_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": False,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": False,
            "r_stroke_hyper": 100,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": False,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": False,
                "r_stroke_hyper": 100,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
    {
        "VERSION": "20251023_square_envs16_2_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": True,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": False,
            "r_stroke_hyper": 100,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": True,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": False,
                "r_stroke_hyper": 100,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
    {
        "VERSION": "20251023_square_envs16_3_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": True,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": True,
            "r_stroke_hyper": 40,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": True,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": True,
                "r_stroke_hyper": 40,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
    {
        "VERSION": "20251023_square_envs16_4_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": False,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": True,
            "r_stroke_hyper": 100,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": False,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": True,
                "r_stroke_hyper": 100,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
    {
        "VERSION": "20251023_square_envs16_3_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": True,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": True,
            "r_stroke_hyper": 40,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": True,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": True,
                "r_stroke_hyper": 40,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
    {
        "VERSION": "20251023_square_envs16_4_1",
        "TOTAL_TIME_STEPS": 5000000,
        "LEARNING_RATE": 0.0003,
        "NUM_ENVS": 16,
        "BATCH_BASE_SIZE": 128,
        "ENT_COEF": 0.01,

        "ENV_CONFIG": {
            "target_sketches_path": TRAIN_SKETCH_DIR,
            "canvas_size": [32, 32],
            "max_steps": 1000,
            "brush_size": 3,
            "target_square_size": 15,
            "use_reward_map_reward": True,
            "reward_map_on_target": 0.1,
            "reward_map_near_target": 0.0,
            "reward_map_far_target": -0.1,
            "reward_map_near_distance": 2,
            "use_budget_channel": False,
            "dynamic_budget_channel": False,
            "stroke_budget": 100,
            "use_stroke_reward": True,
            "r_stroke_hyper": 100,
            "stroke_reward_scale": 1.0,
            "render_mode": None,
            "similarity_weight": 0,
            "use_step_similarity_reward": False,
            "block_reward_scale": 0.0,
            "block_size": 8,
        },

        "VALIDATION_CONFIG": {
            "EVAL_FREQ": 2048 * 50,
            "ENV_CONFIG": {
                "target_sketches_path": TRAIN_SKETCH_DIR,
                "canvas_size": [32, 32],
                "max_steps": 1000,
                "brush_size": 3,
                "target_square_size": 15,
                "use_reward_map_reward": True,
                "reward_map_on_target": 0.1,
                "reward_map_near_target": 0.0,
                "reward_map_far_target": -0.1,
                "reward_map_near_distance": 2,
                "use_budget_channel": False,
                "dynamic_budget_channel": False,
                "stroke_budget": 100,
                "use_stroke_reward": True,
                "r_stroke_hyper": 100,
                "stroke_reward_scale": 1.0,
                "render_mode": None,
                "similarity_weight": 0,
                "use_step_similarity_reward": False,
                "block_reward_scale": 0.0,
                "block_size": 8,
            }
        }
    },
]

if __name__ == '__main__':
    total_experiments = len(experiments)
    for i, config in enumerate(experiments):
        print(f"\n\n<<<<<<<<<< Starting Experiment {i+1}/{total_experiments} >>>>>>>>>>")
        try:
            run_training(config)
            print(f">>>>>>>>>> Experiment {config['VERSION']} Finished Successfully! <<<<<<<<<<")
        except Exception as e:
            print(f"!!!!!!!! Experiment {config['VERSION']} Failed with Error: {e} !!!!!!!!")

    print("\n\nAll experiments have been completed!")